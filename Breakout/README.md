# Breakout

The objective of the breakout game is to hit as many blocks as possible without missing the ball. The action space in the GYM implementation has four actions, do nothing, right, left and fire a new ball.

## Breakout_SL:

This code contains a random agent playing the game and we can notice that it's extremely bad. This is important to compare it later with other agents. 

We have also an AI agent which calculates the paddle and ball position and depending on this information moves. The functions used to calculate the ball and paddle x coordinate are entirely made by ourselves. As you will see in the code or by watching this agent in the folder data/results it performs very good. The objective of this AI agent was to check the implementation of the functions calculate_ball() and calculate_paddle(). 

Finally we have the supervised learning agent that uses the information generated by the AI agent playing games to train. The input size for this agent is an image and it uses a convolutional neural network.

The code structure is very similar to the Lunar Lander example. In fact, we adapted this code from the LunarLander file. Some changes have been made to make it work.

First of all we noticed that with images we were not able to achieve significant result due the training time required. The original observation space (information for the agent) was an image of (210,160,3) and we changed to a vector of dimension 2 that contains the ball and paddle position. Also we have changed the reward which we calculated in terms of the distance between the paddle and the ball.

Credits to :  

https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html

https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning/DeepQLearning.
